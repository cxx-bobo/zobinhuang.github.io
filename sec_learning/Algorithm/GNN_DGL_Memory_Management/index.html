<!DOCTYPE html>
<html lang="cn">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.zobinhuang.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":180,"display":"hide","padding":10,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#FF4136","save":"manual"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="MathJax &#x3D; {         tex: {             inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],             displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],             processEscapes: true,             process">
<meta property="og:type" content="website">
<meta property="og:title" content="源码解析：DGL 的内存管理方法">
<meta property="og:url" content="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Memory_Management/index.html">
<meta property="og:site_name" content="Zobin">
<meta property="og:description" content="MathJax &#x3D; {         tex: {             inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],             displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],             processEscapes: true,             process">
<meta property="og:locale">
<meta property="og:image" content="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png">
<meta property="og:image" content="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Memory_Management/pic/dgl_tensor_storage.png">
<meta property="og:image" content="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Memory_Management/pic/xxx.png">
<meta property="article:published_time" content="2022-07-21T15:50:02.846Z">
<meta property="article:modified_time" content="2022-07-21T15:50:02.846Z">
<meta property="article:author" content="Zhuobin Huang">
<meta property="article:tag" content="Zobin">
<meta property="article:tag" content="黄卓彬">
<meta property="article:tag" content="zobinHuang">
<meta property="article:tag" content="网络工程">
<meta property="article:tag" content="Networking Engineering">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png">

<link rel="canonical" href="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Memory_Management/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : false,
    lang   : 'cn'
  };
</script>

  <title>源码解析：DGL 的内存管理方法 | Zobin
</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Zobin" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="تشغيل شريط التصفح">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zobin</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Loves Tech & Tea</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-主页">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>主页</a>

  </li>
        <li class="menu-item menu-item-关于我">

    <a href="/sec_about/" rel="section"><i class="fa fa-address-card fa-fw"></i>关于我</a>

  </li>
        <li class="menu-item menu-item-知识库">

    <a href="/sec_learning/" rel="section"><i class="fa fa-book-open fa-fw"></i>知识库</a>

  </li>
        <li class="menu-item menu-item-进度">

    <a href="/sec_schedule/" rel="section"><i class="fa fa-calendar-alt fa-fw"></i>进度</a>

  </li>
        <li class="menu-item menu-item-独立音乐人">

    <a href="/sec_music/" rel="section"><i class="fa fa-music fa-fw"></i>独立音乐人</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
  
  

          <div class="content page posts-expand">
            

    
    
    
    <div class="post-block" lang="cn">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">源码解析：DGL 的内存管理方法
</h1>

<div class="post-meta">
  
  <ul class="breadcrumb">
          
            <li><a href="/sec_learning/">SEC_LEARNING</a></li>
            <li><a href="/sec_learning/Algorithm/">ALGORITHM</a></li>
          <li>GNN_DGL_MEMORY_MANAGEMENT</li>
        
  </ul>

</div>

</header>

      
      
      
      <div class="post-body">
          <head>
<!--导入样式表-->
<link rel="stylesheet" type="text/css" href="style/index.css">

<!--导入网页脚本-->
<script src="script/index.js"></script>

<!--支持伪代码显示-->
<script>
    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3.0.0/es5/tex-chtml.js"
        integrity="sha256-3Fdoa5wQb+JYfEmTpQHx9sc/GuwpfC/0R9EpBki+mf8=" crossorigin>
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js">
</script>

<!--支持网页公式显示-->    
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>

<!--支持矩阵显示-->
<script type="text/javascript">
  run_maths = function() {
    if (document.querySelector('[class*="cmath"]') !== null) {
      if (typeof (mjax_path)=='undefined') { mjax_path='https://cdn.jsdelivr.net/npm/mathjax@2'; }
      if (typeof (mjax_config)=='undefined') { mjax_config='AM_CHTML'; }
      smjax = document.createElement ('script');
      smjax.setAttribute('src',`${mjax_path}/MathJax.js?config=${mjax_config}`);
      smjax.setAttribute('async',true);
      document.getElementsByTagName('head')[0].appendChild(smjax);
    }
  };
  if (document.readyState === 'loading') {  
    window.addEventListener('DOMContentLoaded', run_maths); 
  } else { 
    run_maths(); 
  }
</script>
</head>

<body onload="load_page()">

<div align="center" class="div_indicate_source">
  <h4>⚠ 转载请注明出处：<font color="red"><i>作者：ZobinHuang，更新日期：July.21 2022</i></font></h4>
</div>
<div class="div_licence">
  <br>
  <div align="center">
      <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="知识共享许可协议" style="border-width:0; margin-left: 20px; margin-right: 20px;" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a>
  </div>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;本<span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" rel="dct:type">作品</span>由 <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName"><b>ZobinHuang</b></span> 采用 <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><font color="red">知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议</font></a> 进行许可，在进行使用或分享前请查看权限要求。若发现侵权行为，会采取法律手段维护作者正当合法权益，谢谢配合。
  </p>
</div>
<br>
<div class="div_catalogue">
  <div align="center">
    <h1> 目录 </h1>
    <p>
    <font size="3px">有特定需要的内容直接跳转到相关章节查看即可。</font>
  </div>
  <div class="div_load_catalogue_alert" id="load_catalogue_alert">正在加载目录...</div>
  <div class="div_catalogue_container" id="catalogue_container">
  </div>
</div><br>

<!-- Start your post here -->
<h2 class="title">Array 存储</h2>
<div class="div_learning_post">
  <h3 class="title">动态链接库侧</h3>
  <div class="img" title="DGL 存储 Tensor 数据的流程">
    <img src="./pic/dgl_tensor_storage.png" width="95%" />
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;DGL 在动态链接库侧使用各种类型的 Array (i.e., <code>IdArray</code>, <code>DegreeArray</code>, etc.) 实现对底层存储的数组数据的包装，这里说的底层存储的数组数据实际上是 DGL 所支持的各个主流后端计算框架 (e.g., PyTorch, TensorFlow, etc.) 等所定义的 Tensor 数据。上图展示了整个流程，下面我们对这个流程对应的代码进行分析。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;首先，在 <code>include/dgl/aten/types.h</code> <cite>dglsrc_include_dgl_aten_type_h</cite> 中，我们可以看到如下的重定义声明:

  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">typedef</span> NDArray IdArray;</span><br><span class="line"><span class="keyword">typedef</span> NDArray DegreeArray;</span><br><span class="line"><span class="keyword">typedef</span> NDArray BoolArray;</span><br><span class="line"><span class="keyword">typedef</span> NDArray IntArray;</span><br><span class="line"><span class="keyword">typedef</span> NDArray FloatArray;</span><br><span class="line"><span class="keyword">typedef</span> NDArray TypeArray;</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;这里的主角 —— <code>NDArray</code>，是在 <code>include/dgl/runtime/ndarray.h</code> <cite>dglsrc_include_dgl_runtime_ndarray_h</cite> 中进行定义的，定义代码摘抄如下所示:

  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*!</span></span><br><span class="line"><span class="comment">* \brief Managed NDArray.</span></span><br><span class="line"><span class="comment">*  The array is backed by reference counted blocks.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">NDArray</span> &#123;</span></span><br><span class="line">  <span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// NDArray 定义的私有结构体</span></span><br><span class="line">  <span class="class"><span class="keyword">struct</span> <span class="title">Container</span>;</span></span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构造函数</span></span><br><span class="line">  NDArray() &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构造函数</span></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="keyword">inline</span> <span class="title">NDArray</span><span class="params">(Container* data)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构造函数</span></span><br><span class="line">  <span class="function"><span class="keyword">inline</span> <span class="title">NDArray</span><span class="params">(<span class="keyword">const</span> NDArray&amp; other)</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// 构造函数</span></span><br><span class="line">  NDArray(NDArray&amp;&amp; other) <span class="comment">// NOLINT(*)</span></span><br><span class="line">      : data_(other.data_) &#123;</span><br><span class="line">    other.data_ = <span class="literal">nullptr</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">/* ...... */</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">private</span>:</span><br><span class="line">  <span class="comment">// Internal Data content</span></span><br><span class="line">  Container* data_&#123;<span class="literal">nullptr</span>&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="title">NDArray::NDArray</span><span class="params">(Container* data)</span></span></span><br><span class="line"><span class="function">  : <span class="title">data_</span><span class="params">(data)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (data_)</span><br><span class="line">    data_-&gt;IncRef();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">inline</span> <span class="title">NDArray::NDArray</span><span class="params">(<span class="keyword">const</span> NDArray&amp; other)</span></span></span><br><span class="line"><span class="function">  : <span class="title">data_</span><span class="params">(other.data_)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (data_)</span><br><span class="line">    data_-&gt;IncRef();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;从上面的 <code>NDArray</code> 的构造函数代码可以发现，<code>NDArray</code> 存储的数据实际上依赖于类型为 <code>NDArray::Conatainer</code> 结构体的私有变量 <code>data_</code>，后者的定义如下所示:

  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">NDArray</span>:</span>:Container &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">  <span class="comment">// <span class="doctag">NOTE:</span> the first part of this structure is the same as</span></span><br><span class="line">  <span class="comment">// DLManagedTensor, note that, however, the deleter</span></span><br><span class="line">  <span class="comment">// is only called when the reference counter goes to 0</span></span><br><span class="line">  <span class="comment">/*!</span></span><br><span class="line"><span class="comment">  * \brief The corresponding dl_tensor field.</span></span><br><span class="line"><span class="comment">  * \note it is important that the first field is DLTensor</span></span><br><span class="line"><span class="comment">  *  So that this data structure is DLTensor compatible.</span></span><br><span class="line"><span class="comment">  *  The head ptr of this struct can be viewed as DLTensor*.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  DLTensor dl_tensor;</span><br><span class="line">  <span class="comment">/*!</span></span><br><span class="line"><span class="comment">  * \brief addtional context, reserved for recycling</span></span><br><span class="line"><span class="comment">  * \note We can attach additional content here</span></span><br><span class="line"><span class="comment">  *  which the current container depend on</span></span><br><span class="line"><span class="comment">  *  (e.g. reference to original memory when creating views).</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="keyword">void</span>* manager_ctx&#123;<span class="literal">nullptr</span>&#125;;</span><br><span class="line">  <span class="comment">/*!</span></span><br><span class="line"><span class="comment">  * \brief Customized deleter</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * \note The customized deleter is helpful to enable</span></span><br><span class="line"><span class="comment">  *  different ways of memory allocator that are not</span></span><br><span class="line"><span class="comment">  *  currently defined by the system.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="keyword">void</span> (*deleter)(Container* self) = <span class="literal">nullptr</span>;</span><br><span class="line">  <span class="comment">/*! \brief default constructor */</span></span><br><span class="line">  Container() &#123;</span><br><span class="line">    dl_tensor.data = <span class="literal">nullptr</span>;</span><br><span class="line">    dl_tensor.ndim = <span class="number">0</span>;</span><br><span class="line">    dl_tensor.shape = <span class="literal">nullptr</span>;</span><br><span class="line">    dl_tensor.strides = <span class="literal">nullptr</span>;</span><br><span class="line">    dl_tensor.byte_offset = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/*! \brief pointer to shared memory */</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;SharedMemory&gt; mem;</span><br><span class="line">  <span class="comment">/*! \brief developer function, increases reference counter */</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">IncRef</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ref_counter_.fetch_add(<span class="number">1</span>, <span class="built_in">std</span>::memory_order_relaxed);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">/*! \brief developer function, decrease reference counter */</span></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">DecRef</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">if</span> (ref_counter_.fetch_sub(<span class="number">1</span>, <span class="built_in">std</span>::memory_order_release) == <span class="number">1</span>) &#123;</span><br><span class="line">      <span class="built_in">std</span>::atomic_thread_fence(<span class="built_in">std</span>::memory_order_acquire);</span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;deleter != <span class="literal">nullptr</span>) &#123;</span><br><span class="line">        (*<span class="keyword">this</span>-&gt;deleter)(<span class="keyword">this</span>);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span>:</span><br><span class="line">  <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">NDArray</span>;</span></span><br><span class="line">  <span class="keyword">friend</span> <span class="class"><span class="keyword">class</span> <span class="title">RPCWrappedFunc</span>;</span></span><br><span class="line">  <span class="comment">/*!</span></span><br><span class="line"><span class="comment">  * \brief The shape container,</span></span><br><span class="line"><span class="comment">  *  can be used for shape data.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int64_t</span>&gt; shape_;</span><br><span class="line">  <span class="comment">/*!</span></span><br><span class="line"><span class="comment">  * \brief The stride container,</span></span><br><span class="line"><span class="comment">  *  can be used for stride data.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int64_t</span>&gt; stride_;</span><br><span class="line">  <span class="comment">/*! \brief The internal array object */</span></span><br><span class="line">  <span class="built_in">std</span>::atomic&lt;<span class="keyword">int</span>&gt; ref_counter_&#123;<span class="number">0</span>&#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">bool</span> pinned_by_dgl_&#123;<span class="literal">false</span>&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<code>NDArray</code> 的实际数据存储依赖于 <code>NDArray::Container</code>。开发人员基于 <code>NDArray::Container</code> 提供的 <code>IncRef</code> 和 <code>DecRef</code> API 可以实现对结构体被引用情况的计数。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;另外我们还可以观察到，<code>NDArray::Container</code> 结构体的实际数据存储实际上依赖于类型为来自 <code>DLPack</code> 库的 <code>DLTensor</code> 的成员变量 <code>dl_tensor</code>。这里在代码注释中说明的一个 trick 是: 把成员变量 <code>dl_tensor</code> 放在 <code>NDArray::Container</code> 定义的起始位置使得 DGL 代码的其他部分可以使用 <code>DLTensor*</code> 指针来指向 <code>NDArray::Container</code> 实例。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;这里说到了来自 <code>DLPack</code> 库的 <code>DLTensor</code>。<code>DLPack</code> 库是为了统一各种计算框架 (e.g., PyTorch, TensorFlow, etc.) 的 Tensor 定义。<code>DLPack</code> 库并不会定义具体的 Tensor 的存储以及操作方法，而是提供了一个接口，使得在一个计算框架中可以使用来自另一种计算框架定义的 Tensor 数据 (p.s., 以共享内存的方式)，具体可以参考 <code>DLPack</code> 库的官方文档 <cite>dlpack</cite> 和官方仓库 <cite>dlpack_repo</cite>。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;下面我们对 <code>DLTensor</code> 的具体定义进行分析，它是在 <code>DLPack</code> 库的 <code>include/dlpack/dlpack.h</code> <cite>dlpacksrc_include_dlpack_dlpack_h</cite> 中定义的，具体定义如下所示:

  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/*!</span></span><br><span class="line"><span class="comment">* \brief Plain C Tensor object, does not manage memory.</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="keyword">typedef</span> <span class="class"><span class="keyword">struct</span> &#123;</span></span><br><span class="line">  <span class="comment">/*!</span></span><br><span class="line"><span class="comment">  * \brief The data pointer points to the allocated data. This will be CUDA</span></span><br><span class="line"><span class="comment">  * device pointer or cl_mem handle in OpenCL. It may be opaque on some device</span></span><br><span class="line"><span class="comment">  * types. This pointer is always aligned to 256 bytes as in CUDA. The</span></span><br><span class="line"><span class="comment">  * `byte_offset` field should be used to point to the beginning of the data.</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * Note that as of Nov 2021, multiply libraries (CuPy, PyTorch, TensorFlow,</span></span><br><span class="line"><span class="comment">  * TVM, perhaps others) do not adhere to this 256 byte aligment requirement</span></span><br><span class="line"><span class="comment">  * on CPU/CUDA/ROCm, and always use `byte_offset=0`.  This must be fixed</span></span><br><span class="line"><span class="comment">  * (after which this note will be updated); at the moment it is recommended</span></span><br><span class="line"><span class="comment">  * to not rely on the data pointer being correctly aligned.</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * For given DLTensor, the size of memory required to store the contents of</span></span><br><span class="line"><span class="comment">  * data is calculated as follows:</span></span><br><span class="line"><span class="comment">  *</span></span><br><span class="line"><span class="comment">  * \code&#123;.c&#125;</span></span><br><span class="line"><span class="comment">  * static inline size_t GetDataSize(const DLTensor* t) &#123;</span></span><br><span class="line"><span class="comment">  *   size_t size = 1;</span></span><br><span class="line"><span class="comment">  *   for (tvm_index_t i = 0; i &lt; t-&gt;ndim; ++i) &#123;</span></span><br><span class="line"><span class="comment">  *     size *= t-&gt;shape[i];</span></span><br><span class="line"><span class="comment">  *   &#125;</span></span><br><span class="line"><span class="comment">  *   size *= (t-&gt;dtype.bits * t-&gt;dtype.lanes + 7) / 8;</span></span><br><span class="line"><span class="comment">  *   return size;</span></span><br><span class="line"><span class="comment">  * &#125;</span></span><br><span class="line"><span class="comment">  * \endcode</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="keyword">void</span>* data;</span><br><span class="line">  <span class="comment">/*! \brief The device of the tensor */</span></span><br><span class="line">  DLDevice device;</span><br><span class="line">  <span class="comment">/*! \brief Number of dimensions */</span></span><br><span class="line">  <span class="keyword">int32_t</span> ndim;</span><br><span class="line">  <span class="comment">/*! \brief The data type of the pointer*/</span></span><br><span class="line">  DLDataType dtype;</span><br><span class="line">  <span class="comment">/*! \brief The shape of the tensor */</span></span><br><span class="line">  <span class="keyword">int64_t</span>* shape;</span><br><span class="line">  <span class="comment">/*!</span></span><br><span class="line"><span class="comment">  * \brief strides of the tensor (in number of elements, not bytes)</span></span><br><span class="line"><span class="comment">  *  can be NULL, indicating tensor is compact and row-majored.</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line">  <span class="keyword">int64_t</span>* strides;</span><br><span class="line">  <span class="comment">/*! \brief The offset in bytes to the beginning pointer to data */</span></span><br><span class="line">  <span class="keyword">uint64_t</span> byte_offset;</span><br><span class="line">&#125; DLTensor;</span><br></pre></td></tr></table></figure>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在 <code>DLTensor</code> 的定义中，类型为 <code>void*</code> 的成员变量 <code>data</code> 用于指向真正存储着 Array 数据的 Tensor (p.s. 来自各种计算框架)，其余的成员变量则用于存储关于 <code>data</code> 指向的 Tensor 的元数据。

  <h3 class="title">Python 侧</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;DGL 在 Python 侧提供了将后端框架 (e.g., PyTorch, TensorFlow, etc.) 定义的 Tensor 数组转化为 <code>NDArray</code> 的 API。我们下面对它们进行分析。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;以 PyTorch 作为后端框架为例，在调用动态链接库中的 <code>_CAPI_DGLHeteroCreateUnitGraphFromCOO</code> API 时，我们可以看到如下代码:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> . <span class="keyword">import</span> backend <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_unitgraph_from_coo</span>(<span class="params">num_ntypes, num_src, num_dst, row, col,</span></span></span><br><span class="line"><span class="function"><span class="params">                              formats, row_sorted=<span class="literal">False</span>, col_sorted=<span class="literal">False</span></span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create a unitgraph graph index from COO format</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    num_ntypes : int</span></span><br><span class="line"><span class="string">        Number of node types (must be 1 or 2).</span></span><br><span class="line"><span class="string">    num_src : int</span></span><br><span class="line"><span class="string">        Number of nodes in the src type.</span></span><br><span class="line"><span class="string">    num_dst : int</span></span><br><span class="line"><span class="string">        Number of nodes in the dst type.</span></span><br><span class="line"><span class="string">    row : utils.Index</span></span><br><span class="line"><span class="string">        Row index.</span></span><br><span class="line"><span class="string">    col : utils.Index</span></span><br><span class="line"><span class="string">        Col index.</span></span><br><span class="line"><span class="string">    formats : list of str.</span></span><br><span class="line"><span class="string">        Restrict the storage formats allowed for the unit graph.</span></span><br><span class="line"><span class="string">    row_sorted : bool, optional</span></span><br><span class="line"><span class="string">        Whether or not the rows of the COO are in ascending order.</span></span><br><span class="line"><span class="string">    col_sorted : bool, optional</span></span><br><span class="line"><span class="string">        Whether or not the columns of the COO are in ascending order within</span></span><br><span class="line"><span class="string">        each row. This only has an effect when ``row_sorted`` is True.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    HeteroGraphIndex</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(formats, <span class="built_in">str</span>):</span><br><span class="line">        formats = [formats]</span><br><span class="line">    <span class="keyword">return</span> _CAPI_DGLHeteroCreateUnitGraphFromCOO(</span><br><span class="line">        <span class="built_in">int</span>(num_ntypes), <span class="built_in">int</span>(num_src), <span class="built_in">int</span>(num_dst),</span><br><span class="line">        F.to_dgl_nd(row), F.to_dgl_nd(col),</span><br><span class="line">        formats, row_sorted, col_sorted)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<code>_CAPI_DGLHeteroCreateUnitGraphFromCOO</code> 的定义如下所示:

  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">DGL_REGISTER_GLOBAL(<span class="string">&quot;heterograph_index._CAPI_DGLHeteroCreateUnitGraphFromCOO&quot;</span>)</span><br><span class="line">.set_body([] (DGLArgs args, DGLRetValue* rv) &#123;</span><br><span class="line">    <span class="keyword">int64_t</span> nvtypes = args[<span class="number">0</span>];</span><br><span class="line">    <span class="keyword">int64_t</span> num_src = args[<span class="number">1</span>];</span><br><span class="line">    <span class="keyword">int64_t</span> num_dst = args[<span class="number">2</span>];</span><br><span class="line">    IdArray row = args[<span class="number">3</span>];</span><br><span class="line">    IdArray col = args[<span class="number">4</span>];</span><br><span class="line">    List&lt;Value&gt; formats = args[<span class="number">5</span>];</span><br><span class="line">    <span class="keyword">bool</span> row_sorted = args[<span class="number">6</span>];</span><br><span class="line">    <span class="keyword">bool</span> col_sorted = args[<span class="number">7</span>];</span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;SparseFormat&gt; formats_vec;</span><br><span class="line">    <span class="keyword">for</span> (Value val : formats) &#123;</span><br><span class="line">      <span class="built_in">std</span>::<span class="built_in">string</span> fmt = val-&gt;data;</span><br><span class="line">      formats_vec.push_back(ParseSparseFormat(fmt));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">auto</span> code = SparseFormatsToCode(formats_vec);</span><br><span class="line">    <span class="keyword">auto</span> hgptr = CreateFromCOO(nvtypes, num_src, num_dst, row, col,</span><br><span class="line">        row_sorted, col_sorted, code);</span><br><span class="line">    *rv = HeteroGraphRef(hgptr);</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;可以发现，<code>_CAPI_DGLHeteroCreateUnitGraphFromCOO</code> 接受的第 3 个和第 4 个参数均是类型为 <code>IdArray</code> 的参数，其实质类型为 <code>NDArray</code>。在 Python 侧调用该 API 时，我们发现程序使用了 <code>F.to_dgl_nd</code> 这个 API，将 <code>torch.tensor</code> 数据转化为了 <code>NDArray</code> 数据。<code>F.to_dgl_nd</code> 是在 <code>python/dgl/backend/__init__.py</code> <cite>dglsrc_python_dgl_backend_init_py</cite> 中定义的，如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_dgl_nd</span>(<span class="params">data</span>):</span></span><br><span class="line">  <span class="keyword">return</span> zerocopy_to_dgl_ndarray(data)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;上面的代码中，<code>zerocopy_to_dgl_ndarray</code> 的实现取决于具体的后端实现框架。我们这里以 PyTorch 为例的话，<code>zerocopy_to_dgl_ndarray</code> 是在 <code>backend/pytorch/tensor.py</code> <cite>dglsrc_python_dgl_backend_pytorch_tensor_py</cite> 中进行定义的，如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch.utils <span class="keyword">import</span> dlpack</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> LooseVersion(th.__version__) &gt;= LooseVersion(<span class="string">&quot;1.10.0&quot;</span>):</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">zerocopy_to_dgl_ndarray</span>(<span class="params">data</span>):</span></span><br><span class="line">        <span class="keyword">if</span> data.dtype == th.<span class="built_in">bool</span>:</span><br><span class="line">            data = data.byte()</span><br><span class="line">        <span class="keyword">return</span> nd.from_dlpack(dlpack.to_dlpack(data.contiguous()))</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">zerocopy_to_dgl_ndarray</span>(<span class="params">data</span>):</span></span><br><span class="line">        <span class="keyword">return</span> nd.from_dlpack(dlpack.to_dlpack(data.contiguous()))</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;从上面的代码中可以看出，<code>zerocopy_to_dgl_ndarray</code> 首先使用 <code>torch.utils.dlpack.to_dlpack</code> API，将一个 PyTorch 的 Tensor 数据以零内存拷贝的方式转化为通用的 <code>DLPack</code> 实例，然后再调用 DGL 的 <code>NDArray.from_dlpack</code> API 将 <code>DLPack</code> 实例转化为 DGL 的 <code>NDArray</code> 实例，后者这个 API 的底层将调用动态链接库中的方法实现相应的转化，我们在这里不再细究。
</div> 


<div class="div_ref" id="ref_container"></div>

</body>


<!--图片、引用-->
<!-- 
<div class="img" title="img title" label="img_label" source="url">
  <img src="" height="" />
</div>

<imaging>img_label</imaging>
-->

<!--等式、引用-->
<!-- 
<div class="equation" label="equation_label">
</div>

<equation>equation_label</equation>
-->

<!--定理、引用、证明-->
<!-- 
<div class="theorm" label="theorm_label">
</div>

<theorm>theorm_label</theorm>

<div class="theorm_prove">
</div>
-->

<!--引用其它章节-->
<!-- 
<ref></ref> 
-->

<!--引用文献-->
<!-- 
<cite></cite> 
-->

<!--关键词-->
<!-- 
<def></def> 
-->

<!--醒目注意-->
<!-- 
<note></note> 
-->

<!--表格-->
<!--
<table border="1" align="center" bgcolor="#FFFFFF">
  <caption>表格</caption>
  <tr>
    <th>A</th>
    <th>B</th>
    <th>C</th>
  </tr>
  <tr>
    <td>xxx</td>
    <td>xxx</td>
    <td>xxx</td>
  </tr>
</table>
-->

<!--矩阵公式-->
<!--
<div class="cmath" align="center">
  `((1, 0),(1, 0))`
</div><br>
-->

<!--伪代码-->
<!--
<pre id="quicksort" style="display:hidden;">
  % This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
  \begin{algorithm}
  \caption{Quicksort}
  \begin{algorithmic}
  \PROCEDURE{Quicksort}{$A, p, r$}
      % Add Here

      % 空行
      % \STATE \texttt{\\}
  \ENDPROCEDURE
  \end{algorithmic}
  \end{algorithm}
</pre>
<script>
    pseudocode.renderElement(document.getElementById("quicksort"));
</script>
-->
<!--
Latex 伪代码格式见: https://github.com/SaswatPadhi/pseudocode.js
-->

<!--图片-->
<!--
<div align="center">
  <img src="./pic/xxx.png" width=80%>
</div>
-->

<!--正文-->
<!--
<p>
&nbsp;&nbsp;&nbsp;&nbsp;公式：<span>`\overline{A}\overline{B}`</span>
</p>
-->
      </div>
      
      
      
    </div>
    
  <ul class="breadcrumb">
          
            <li><a href="/sec_learning/">SEC_LEARNING</a></li>
            <li><a href="/sec_learning/Algorithm/">ALGORITHM</a></li>
          <li>GNN_DGL_MEMORY_MANAGEMENT</li>
        
  </ul>

    
    
    


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          المحتويات
        </li>
        <li class="sidebar-nav-overview">
          عام
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhuobin Huang"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Zhuobin Huang</p>
  <div class="site-description" itemprop="description">System Engineer</div>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zobinHuang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zobinHuang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zobin1999@gmail.com" title="E-Mail → mailto:zobin1999@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.weibo.com/u/2861056530" title="Weibo → https:&#x2F;&#x2F;www.weibo.com&#x2F;u&#x2F;2861056530" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/HwangZobin" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;HwangZobin" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">粤ICP备2021044371号 </a>
  </div>

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-guitar"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhuobin Huang</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>















  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'y8LMT8RtOsi4JsbYHtNm2J7U-gzGzoHsz',
      appKey     : 'Q0cSe4rR8Iwr0Gs60rwWBsYa',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
