<!DOCTYPE html>
<html lang="cn">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Noto Serif SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"www.zobinhuang.com","root":"/","scheme":"Pisces","version":"7.8.0","exturl":false,"sidebar":{"position":"left","width":180,"display":"hide","padding":10,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":true,"color":"#FF4136","save":"manual"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}};
  </script>

  <meta name="description" content="MathJax &#x3D; {         tex: {             inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],             displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],             processEscapes: true,             process">
<meta property="og:type" content="website">
<meta property="og:title" content="源码解析：DGL 的图数据存储">
<meta property="og:url" content="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Graph_Construction/index.html">
<meta property="og:site_name" content="Zobin">
<meta property="og:description" content="MathJax &#x3D; {         tex: {             inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]],             displayMath: [[&#39;$$&#39;,&#39;$$&#39;], [&#39;\\[&#39;,&#39;\\]&#39;]],             processEscapes: true,             process">
<meta property="og:locale">
<meta property="og:image" content="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png">
<meta property="og:image" content="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Graph_Construction/pic/unit_graph.png">
<meta property="og:image" content="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Graph_Construction/pic/metagraph.png">
<meta property="og:image" content="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Graph_Construction/pic/metagraph_of_unitgraph.png">
<meta property="og:image" content="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Graph_Construction/pic/coo.png">
<meta property="og:image" content="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Graph_Construction/pic/csr.png">
<meta property="og:image" content="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Graph_Construction/pic/csc.png">
<meta property="og:image" content="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Graph_Construction/pic/codeflow_create_graph.png">
<meta property="og:image" content="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Graph_Construction/pic/xxx.png">
<meta property="article:published_time" content="2022-07-22T06:51:36.138Z">
<meta property="article:modified_time" content="2022-07-22T06:51:36.138Z">
<meta property="article:author" content="Zhuobin Huang">
<meta property="article:tag" content="Zobin">
<meta property="article:tag" content="黄卓彬">
<meta property="article:tag" content="zobinHuang">
<meta property="article:tag" content="网络工程">
<meta property="article:tag" content="Networking Engineering">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png">

<link rel="canonical" href="http://www.zobinhuang.com:10082/sec_learning/Algorithm/GNN_DGL_Graph_Construction/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : false,
    lang   : 'cn'
  };
</script>

  <title>源码解析：DGL 的图数据存储 | Zobin
</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="Zobin" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Navigationsleiste an/ausschalten">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Zobin</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Loves Tech & Tea</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-主页">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>主页</a>

  </li>
        <li class="menu-item menu-item-关于我">

    <a href="/sec_about/" rel="section"><i class="fa fa-address-card fa-fw"></i>关于我</a>

  </li>
        <li class="menu-item menu-item-知识库">

    <a href="/sec_learning/" rel="section"><i class="fa fa-book-open fa-fw"></i>知识库</a>

  </li>
        <li class="menu-item menu-item-进度">

    <a href="/sec_schedule/" rel="section"><i class="fa fa-calendar-alt fa-fw"></i>进度</a>

  </li>
        <li class="menu-item menu-item-独立音乐人">

    <a href="/sec_music/" rel="section"><i class="fa fa-music fa-fw"></i>独立音乐人</a>

  </li>
  </ul>
</nav>




</div>
    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
  
  

          <div class="content page posts-expand">
            

    
    
    
    <div class="post-block" lang="cn">
      <header class="post-header">

<h1 class="post-title" itemprop="name headline">源码解析：DGL 的图数据存储
</h1>

<div class="post-meta">
  
  <ul class="breadcrumb">
          
            <li><a href="/sec_learning/">SEC_LEARNING</a></li>
            <li><a href="/sec_learning/Algorithm/">ALGORITHM</a></li>
          <li>GNN_DGL_GRAPH_CONSTRUCTION</li>
        
  </ul>

</div>

</header>

      
      
      
      <div class="post-body">
          <head>
<!--导入样式表-->
<link rel="stylesheet" type="text/css" href="style/index.css">

<!--导入网页脚本-->
<script src="script/index.js"></script>

<!--支持伪代码显示-->
<script>
    MathJax = {
        tex: {
            inlineMath: [['$','$'], ['\\(','\\)']],
            displayMath: [['$$','$$'], ['\\[','\\]']],
            processEscapes: true,
            processEnvironments: true,
        }
    }
</script>
<script src="https://cdn.jsdelivr.net/npm/mathjax@3.0.0/es5/tex-chtml.js"
        integrity="sha256-3Fdoa5wQb+JYfEmTpQHx9sc/GuwpfC/0R9EpBki+mf8=" crossorigin>
</script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.css">
<script src="https://cdn.jsdelivr.net/npm/pseudocode@latest/build/pseudocode.min.js">
</script>

<!--支持网页公式显示-->    
<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=AM_HTMLorMML-full"></script>

<!--支持矩阵显示-->
<script type="text/javascript">
  run_maths = function() {
    if (document.querySelector('[class*="cmath"]') !== null) {
      if (typeof (mjax_path)=='undefined') { mjax_path='https://cdn.jsdelivr.net/npm/mathjax@2'; }
      if (typeof (mjax_config)=='undefined') { mjax_config='AM_CHTML'; }
      smjax = document.createElement ('script');
      smjax.setAttribute('src',`${mjax_path}/MathJax.js?config=${mjax_config}`);
      smjax.setAttribute('async',true);
      document.getElementsByTagName('head')[0].appendChild(smjax);
    }
  };
  if (document.readyState === 'loading') {  
    window.addEventListener('DOMContentLoaded', run_maths); 
  } else { 
    run_maths(); 
  }
</script>
</head>

<body onload="load_page()">

<div align="center" class="div_indicate_source">
  <h4>⚠ 转载请注明出处：<font color="red"><i>作者：ZobinHuang，更新日期：June 22 2022</i></font></h4>
</div>
<div class="div_licence">
  <br>
  <div align="center">
      <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><img alt="知识共享许可协议" style="border-width:0; margin-left: 20px; margin-right: 20px;" src="https://i.creativecommons.org/l/by-nc-nd/4.0/88x31.png" /></a>
  </div>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;本<span xmlns:dct="http://purl.org/dc/terms/" href="http://purl.org/dc/dcmitype/Text" rel="dct:type">作品</span>由 <span xmlns:cc="http://creativecommons.org/ns#" property="cc:attributionName"><b>ZobinHuang</b></span> 采用 <a rel="license noopener" target="_blank" href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><font color="red">知识共享署名-非商业性使用-禁止演绎 4.0 国际许可协议</font></a> 进行许可，在进行使用或分享前请查看权限要求。若发现侵权行为，会采取法律手段维护作者正当合法权益，谢谢配合。
  </p>
</div>
<br>
<div class="div_catalogue">
  <div align="center">
    <h1> 目录 </h1>
    <p>
    <font size="3px">有特定需要的内容直接跳转到相关章节查看即可。</font>
  </div>
  <div class="div_load_catalogue_alert" id="load_catalogue_alert">正在加载目录...</div>
  <div class="div_catalogue_container" id="catalogue_container">
  </div>
</div><br>

<!-- Start your post here -->
<h2 class="title">预备知识</h2>
<div class="div_learning_post">
  <h3 class="title">单元图 (Unit Graph)</h3>
  <label class="title">unit_graph</label>
  <div class="img" title="单元图示意图">
    <img src="./pic/unit_graph.png" width="600px"/>
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在 DGL 中，底层使用的是 <def>单元图 (Unit Graph)</def> 来存储顶层的图拓扑信息。所谓单元图，根据 DGL 的文档 <cite>dgl_doc_heterogeneous_graphs</cite> 和在动态链接库代码中的注释 <cite>dglsrc_src_graph_unit_graph_cc</cite>，是只包含一种关系 <code>(utype, etype, vtype)</code> 的图。在只有一种关系的定义下，单元图有如下两种情况:

  <ul>
    <li><b>有向图</b>: <code>utype</code> 和 <code>vtype</code> 分属于两种不同类型；</li>
    <li><b>无向图</b>: <code>utype</code> 和 <code>vtype</code> 类型相同</li>
  </ul>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于 <def>同构图 (heterogeneous graph)</def> (i.e. 全图只有一种类型的点) 和 <def>二分图 (bipartite)</def> 来说，它们天然就满足单元图的定义，因此都是单元图；对于 <def>异构图 (heterogeneous graph)</def> (i.e. 存在多种类型的点，以及边关系) 来说，DGL 底层会将其拆解为若干个只包含一种关系 <code>(utype, etype, vtype)</code> 的图进行存储，也即单元图。

  <h3 class="title">元图 (Meta Graph)</h3>
  <label class="title">metagraph</label>

  <div class="img" title="元图示意图">
    <img src="./pic/metagraph.png" width="600px"/>
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;元图 <code>Meta Graph</code> 是基于异构图所产生出来的概念。元图中的各个点代表了异构图中的各个点的种类；元图中的边代表了异构图中各类点之间的邻接关系。元图的示意图如上所示。

  <div class="img" title="Unit Graph 的元图的两种情况">
    <img src="./pic/metagraph_of_unitgraph.png" width="600px"/>
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;值得注意的是，对于 Unit Graph 来说，其 Meta Graph 的形式只有如上图所示的两种情况，分别对应有向图和无向图的情况。

  <h3 class="title">图拓扑的存储方法</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于一张 Unit Graph，我们现在来关心其在计算机上的图拓扑的存储方法。首先，大部分图数据集中所使用的图拓扑大都十分稀疏 (i.e. 一个(简单)图中边的数量上限是 $O(n^2)$，这也是邻接矩阵的元素个数，大部分图数据集的拓扑都达不到这个数量级，导致邻接矩阵较为稀疏)，因此应该使用更加存储高效的方法，而不是邻接矩阵来存储稀疏的图拓扑数据。下面介绍典型的几种存储稀疏矩阵的方法。

  <div class="img" title="COO 存储方法">
    <img src="./pic/coo.png" width="600px"/>
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;首先是 <def>Coordinate list (COO)</def> 方法，如上图所示，COO 仅记录了稀疏矩阵中非零元素的坐标以及对应的值的信息，就缩小了存储稀疏矩阵所需要的存储空间。

  <div class="img" title="CSR 存储方法">
    <img src="./pic/csr.png" width="600px"/>
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;接着是 <def>Compressed Sparse Row (CSR)</def> 方法，如上图所示，CSR 相对于 COO 进一步优化了存储策略：我们可以观察到在 COO 方法中，Row 信息的记录实际上存在冗余，因为其重复记录了同一行不同列的矩阵元素的行信息；因此 CSR 方法通过把 Row 信息更改为 Row 指针，只记录属于同一行不通列的矩阵元素在 Column 中的起始位置，消除了该冗余性，进一步提高了存储效率。

  <div class="img" title="CSC 存储方法">
    <img src="./pic/csc.png" width="600px"/>
  </div>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;最后是 <def>Compressed Sparse Column (CSC)</def> 方法，其根本思想与 CSR 别无二致，只是把行换成了列，这里不再赘述。
</div>

<h2 class="title">图拓扑创建和存储的 DGL 实现</h2>
<div class="div_learning_post">
  <h3 class="title">DGL 顶层用户 API</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;DGL 使用一个唯一的整数来表示一个节点，称为点 ID，并用对应的两个端点 ID 表示一条边。同时，DGL 也会根据边被添加的顺序，给每条边分配一个唯一的整数编号，称为边 ID。节点和边的 ID 都是从 $0$ 开始构建的。在 DGL 的图里，所有的边都是有方向的，即边 $(u,v)$ 表示它是从节点 $u$ 指向节点 $v$ 的。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;我们首先考虑同构图这种比较简单的情况。DGL 中使用 <code>DGLGraph</code> 来代表一个同构图，创建一个 <code>DGLGraph</code> 对象的一种方法是使用 <code>dgl.graph</code> 函数。它接受一个边的集合作为输入。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> th</span><br><span class="line"></span><br><span class="line"><span class="comment"># 边 0-&gt;1, 0-&gt;2, 0-&gt;3, 1-&gt;3</span></span><br><span class="line">u, v = th.tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">g = dgl.graph((u, v))</span><br><span class="line">print(g) <span class="comment"># 图中节点的数量是 DGL 通过给定的图的边列表中最大的点ID推断所得出的</span></span><br><span class="line">Graph(num_nodes=<span class="number">4</span>, num_edges=<span class="number">4</span>,</span><br><span class="line">      ndata_schemes=&#123;&#125;</span><br><span class="line">      edata_schemes=&#123;&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取节点的 ID</span></span><br><span class="line">print(g.nodes())</span><br><span class="line"><span class="comment"># tensor([0, 1, 2, 3])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取边的对应端点</span></span><br><span class="line">print(g.edges())</span><br><span class="line"><span class="comment"># (tensor([0, 0, 0, 1]), tensor([1, 2, 3, 3]))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取边的对应端点和边 ID</span></span><br><span class="line">print(g.edges(form=<span class="string">&#x27;all&#x27;</span>))</span><br><span class="line"><span class="comment"># (tensor([0, 0, 0, 1]), tensor([1, 2, 3, 3]), tensor([0, 1, 2, 3]))</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 如果具有最大 ID 的节点没有边，在创建图的时候，用户需要明确地指明节点的数量。</span></span><br><span class="line">g = dgl.graph((u, v), num_nodes=<span class="number">8</span>)</span><br></pre></td></tr></table></figure>
  <h3 class="title">DGL 实现: 创建图拓扑</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;下面我们对 <code>dgl.graph</code> 这个 API 背后的代码细节进行分析。DGL 初始化一个图的 Code Flow 如下所示。

  <div class="img" title="创建图拓扑 Code Flow">
    <img src="./pic/codeflow_create_graph.png" width="800px"/>
  </div>

  <h4 class="title">对输入格式进行匹配和转换</h4>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;我们在上面的代码的 Line 6 中 调用的用于创建图对象的 <code>dgl.graph</code> 函数是在 <code>dgl/convert.py</code> <cite>dglsrc_convert_py</cite> 下定义的 (p.s. 这个文件定义了若干 API，用于将其它形式的图拓扑数据转化为 DGL 图对象)。我们向 <code>dgl.graph</code> 函数中传入了由两个 <code>torch.tensor</code> 组成的 tuple 代表了 COO 形式的图拓扑存储方法。<code>dgl.graph</code> 的代码定义摘抄如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">graph</span>(<span class="params">data,</span></span></span><br><span class="line"><span class="function"><span class="params">        ntype=<span class="literal">None</span>, etype=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        *,</span></span></span><br><span class="line"><span class="function"><span class="params">        num_nodes=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        idtype=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        device=<span class="literal">None</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        row_sorted=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        col_sorted=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">        **deprecated_kwargs</span>):</span></span><br><span class="line"></span><br><span class="line">  (sparse_fmt, arrays), urange, vrange = utils.graphdata2tensors(data, idtype)</span><br><span class="line">  <span class="keyword">if</span> num_nodes <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:  <span class="comment"># override the number of nodes</span></span><br><span class="line">      <span class="keyword">if</span> num_nodes &lt; <span class="built_in">max</span>(urange, vrange):</span><br><span class="line">          <span class="keyword">raise</span> DGLError(<span class="string">&#x27;The num_nodes argument must be larger than the max ID in the data,&#x27;</span></span><br><span class="line">                         <span class="string">&#x27; but got &#123;&#125; and &#123;&#125;.&#x27;</span>.<span class="built_in">format</span>(num_nodes, <span class="built_in">max</span>(urange, vrange) - <span class="number">1</span>))</span><br><span class="line">      urange, vrange = num_nodes, num_nodes</span><br><span class="line"></span><br><span class="line">  g = create_from_edges(sparse_fmt, arrays, <span class="string">&#x27;_N&#x27;</span>, <span class="string">&#x27;_E&#x27;</span>, <span class="string">&#x27;_N&#x27;</span>, urange, vrange,</span><br><span class="line">                        row_sorted=row_sorted, col_sorted=col_sorted)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> g.to(device)</span><br></pre></td></tr></table></figure>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;值得注意的是，传入 <code>dgl.graph</code> 的 tuple 类型的参数 <code>data</code> 可以接受以下几种常见格式:

  <ul>
    <li><code>("coo", torch.tensor, torch.tensor)</code>: 显式指明使用的稀疏矩阵存储方法，并且通过两个 <code>torch.tensor</code> 对象传入拓扑信息;</li>
    <li><code>(torch.tensor, torch.tensor)</code>: 不指明使用的稀疏矩阵存储方法，会被 DGL 一概当作 COO 格式处理;</li>
    <li><code>("coo", list, list)</code>: 显式指明使用的稀疏矩阵存储方法，并且通过两个 Python List 传入拓扑信息</li>
    <li><code>(list, list)</code>: 不指明使用的稀疏矩阵存储方法</li>
  </ul>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;为了应对 tuple 中不同的信息格式，在 Line 11 调用了 <code>utils.graphdata2tensors</code> 函数对输入的 tuple 进行统一处理，该函数最终返回了以下 4 个信息:

  <ul>
    <li><code>sparse_fmt</code>: 字符串，代表稀疏矩阵存储格式，可取值有: <code>"coo"</code>, <code>"csc"</code>, <code>"csr"</code>；</li>
    <li><code>arrays</code>: <code>(torch.tensor, torch.tensor)</code> 的 tuple，代表了在对应的稀疏矩阵存储格式下的图拓扑信息；</li>
    <li><code>urange</code>: 源节点的个数；</li>
    <li><code>vrange</code>: 目的节点的个数</li>
  </ul>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;这里使用的 <code>utils.graphdata2tensors</code> 函数是在 <code>dgl/utils/data.py</code> <cite>dglsrc_utils_data_py</cite> 中定义的，代码细节摘抄如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> collections <span class="keyword">import</span> namedtuple</span><br><span class="line"></span><br><span class="line">SparseAdjTuple = namedtuple(<span class="string">&#x27;SparseAdjTuple&#x27;</span>, [<span class="string">&#x27;format&#x27;</span>, <span class="string">&#x27;arrays&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">graphdata2tensors</span>(<span class="params">data, idtype=<span class="literal">None</span>, bipartite=<span class="literal">False</span>, **kwargs</span>):</span></span><br><span class="line">  <span class="comment"># 将 data 元组转化为 SparseAdjTuple</span></span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">isinstance</span>(data, <span class="built_in">tuple</span>):</span><br><span class="line">      <span class="keyword">if</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(data[<span class="number">0</span>], <span class="built_in">str</span>):</span><br><span class="line">          <span class="comment"># (row, col) format, convert to (&#x27;coo&#x27;, (row, col))</span></span><br><span class="line">          data = (<span class="string">&#x27;coo&#x27;</span>, data)</span><br><span class="line">      data = SparseAdjTuple(*data)</span><br><span class="line">  </span><br><span class="line">  <span class="comment"># 如果没有传入 idType，并且传入的 tuple 的两个元素不是 tensor 时，强行设置 idtype 为 int64。</span></span><br><span class="line">  <span class="comment"># 否则，在后面的代码中我们会看到：</span></span><br><span class="line">  <span class="comment"># [1] 要么使用传入的 idType;</span></span><br><span class="line">  <span class="comment"># [2] 要么传入的 idType 为空，直接从传入的 tensor tuple 中推理出 idtype</span></span><br><span class="line">  <span class="keyword">if</span> idtype <span class="keyword">is</span> <span class="literal">None</span> <span class="keyword">and</span> \</span><br><span class="line">          <span class="keyword">not</span> (<span class="built_in">isinstance</span>(data, SparseAdjTuple) <span class="keyword">and</span> F.is_tensor(data.arrays[<span class="number">0</span>])):</span><br><span class="line">      <span class="comment"># preferred default idtype is int64</span></span><br><span class="line">      <span class="comment"># if data is tensor and idtype is None, infer the idtype from tensor</span></span><br><span class="line">      idtype = F.int64</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 检查 idtype 是否为 None, int32, int64 中的一种</span></span><br><span class="line">  checks.check_valid_idtype(idtype)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># 如果传入的 tutle 的两个元素不是 tensor 时，将 Iterable 的对象转化为 tensor</span></span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">isinstance</span>(data, SparseAdjTuple) <span class="keyword">and</span> (<span class="keyword">not</span> <span class="built_in">all</span>(F.is_tensor(a) <span class="keyword">for</span> a <span class="keyword">in</span> data.arrays)):</span><br><span class="line">      <span class="comment"># (Iterable, Iterable) type data, convert it to (Tensor, Tensor)</span></span><br><span class="line">      <span class="keyword">if</span> <span class="built_in">len</span>(data.arrays[<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">          <span class="comment"># force idtype for empty list</span></span><br><span class="line">          data = SparseAdjTuple(data.<span class="built_in">format</span>, <span class="built_in">tuple</span>(F.tensor(a, idtype) <span class="keyword">for</span> a <span class="keyword">in</span> data.arrays))</span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          <span class="comment"># convert the iterable to tensor and keep its native data type so we can check</span></span><br><span class="line">          <span class="comment"># its validity later</span></span><br><span class="line">          data = SparseAdjTuple(data.<span class="built_in">format</span>, <span class="built_in">tuple</span>(F.tensor(a) <span class="keyword">for</span> a <span class="keyword">in</span> data.arrays))</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">isinstance</span>(data, SparseAdjTuple):</span><br><span class="line">      <span class="comment"># 如果传入的 idType 不为空，使用传入的 idType</span></span><br><span class="line">      <span class="keyword">if</span> idtype <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">          data = SparseAdjTuple(data.<span class="built_in">format</span>, <span class="built_in">tuple</span>(F.astype(a, idtype) <span class="keyword">for</span> a <span class="keyword">in</span> data.arrays))</span><br><span class="line"></span><br><span class="line">      <span class="comment"># 推断图中的源节点和目的节点的数目</span></span><br><span class="line">      num_src, num_dst = infer_num_nodes(data, bipartite=bipartite)</span><br><span class="line">  </span><br><span class="line">  <span class="keyword">return</span> data, num_src, num_dst</span><br></pre></td></tr></table></figure>
  <h4 class="title">调用动态链接库创建图底层存储</h4>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;回到 <code>dgl.graph</code> 函数，在完成对输入 tuple 的统一后，Line 18 调用了位于同一个文件 <code>dgl/convert.py</code> <cite>dglsrc_convert_py</cite> 下的 <code>dgl.create_from_edges</code> 函数，基于已知的关于图拓扑的信息，创建出一个 <code>DGLHeteroGraph</code> 实例，该函数的代码细节如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_from_edges</span>(<span class="params">sparse_fmt, arrays,</span></span></span><br><span class="line"><span class="function"><span class="params">                    utype, etype, vtype,</span></span></span><br><span class="line"><span class="function"><span class="params">                    urange, vrange,</span></span></span><br><span class="line"><span class="function"><span class="params">                    row_sorted=<span class="literal">False</span>,</span></span></span><br><span class="line"><span class="function"><span class="params">                    col_sorted=<span class="literal">False</span></span>):</span></span><br><span class="line">  <span class="keyword">if</span> utype == vtype:</span><br><span class="line">      num_ntypes = <span class="number">1</span></span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      num_ntypes = <span class="number">2</span></span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> sparse_fmt == <span class="string">&#x27;coo&#x27;</span>:</span><br><span class="line">      u, v = arrays</span><br><span class="line">      hgidx = heterograph_index.create_unitgraph_from_coo(</span><br><span class="line">          num_ntypes, urange, vrange, u, v, [<span class="string">&#x27;coo&#x27;</span>, <span class="string">&#x27;csr&#x27;</span>, <span class="string">&#x27;csc&#x27;</span>],</span><br><span class="line">          row_sorted, col_sorted)</span><br><span class="line">  <span class="keyword">else</span>:   <span class="comment"># &#x27;csr&#x27; or &#x27;csc&#x27;</span></span><br><span class="line">      indptr, indices, eids = arrays</span><br><span class="line">      hgidx = heterograph_index.create_unitgraph_from_csr(</span><br><span class="line">          num_ntypes, urange, vrange, indptr, indices, eids, [<span class="string">&#x27;coo&#x27;</span>, <span class="string">&#x27;csr&#x27;</span>, <span class="string">&#x27;csc&#x27;</span>],</span><br><span class="line">          sparse_fmt == <span class="string">&#x27;csc&#x27;</span>)</span><br><span class="line">  <span class="keyword">if</span> utype == vtype:</span><br><span class="line">      <span class="keyword">return</span> DGLHeteroGraph(hgidx, [utype], [etype])</span><br><span class="line">  <span class="keyword">else</span>:</span><br><span class="line">      <span class="keyword">return</span> DGLHeteroGraph(hgidx, [utype, vtype], [etype])</span><br></pre></td></tr></table></figure>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在 Line 6-9 中，函数首先对传入的 <code>utype</code> (源节点类型) 和 <code>vtype</code> (目的节点类型) 进行一致性判断，从而得出图中节点种类数 <code>num_ntypes</code>。我们在上面 <ref>unit_graph</ref> 中介绍了 DGL 在底层存储图拓扑所依赖的 Unit Graph。在一个 Unit Graph 中，要么点的种类只有两种 (i.e., 有向图)，要么点的种类有一种 (i.e., 无向图)，因此这里的 <code>num_ntypes</code> 的取值范围为 1 或者 2。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;我们在这里调用的 <code>DGLGraph</code> API，在调用 <code>create_from_edges</code> 的时候，传入的 <code>utype</code> 和 <code>vtype</code> 是相同的值 <code>_N</code>，因此 <code>num_ntypes</code> 的取值为 1。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;然后，在 Line 11-20 中，基于稀疏矩阵存储格式的不同，分别调用了 <code>create_unitgraph_from_coo</code> 或者 <code>create_unitgraph_from_csr</code> 函数，这两个函数是在 <code>dgl/heterograph_index.py</code> <cite>dglsrc_heterograph_index_py</cite> 中定义的。以前者为例，我们来看其详细定义:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">create_unitgraph_from_coo</span>(<span class="params">num_ntypes, num_src, num_dst, row, col,</span></span></span><br><span class="line"><span class="function"><span class="params">                            formats, row_sorted=<span class="literal">False</span>, col_sorted=<span class="literal">False</span></span>):</span></span><br><span class="line">  <span class="string">&quot;&quot;&quot;Create a unitgraph graph index from COO format</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Parameters</span></span><br><span class="line"><span class="string">  ----------</span></span><br><span class="line"><span class="string">  num_ntypes : int</span></span><br><span class="line"><span class="string">      Number of node types (must be 1 or 2).</span></span><br><span class="line"><span class="string">  num_src : int</span></span><br><span class="line"><span class="string">      Number of nodes in the src type.</span></span><br><span class="line"><span class="string">  num_dst : int</span></span><br><span class="line"><span class="string">      Number of nodes in the dst type.</span></span><br><span class="line"><span class="string">  row : utils.Index</span></span><br><span class="line"><span class="string">      Row index.</span></span><br><span class="line"><span class="string">  col : utils.Index</span></span><br><span class="line"><span class="string">      Col index.</span></span><br><span class="line"><span class="string">  formats : list of str.</span></span><br><span class="line"><span class="string">      Restrict the storage formats allowed for the unit graph.</span></span><br><span class="line"><span class="string">  row_sorted : bool, optional</span></span><br><span class="line"><span class="string">      Whether or not the rows of the COO are in ascending order.</span></span><br><span class="line"><span class="string">  col_sorted : bool, optional</span></span><br><span class="line"><span class="string">      Whether or not the columns of the COO are in ascending order within</span></span><br><span class="line"><span class="string">      each row. This only has an effect when ``row_sorted`` is True.</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">  Returns</span></span><br><span class="line"><span class="string">  -------</span></span><br><span class="line"><span class="string">  HeteroGraphIndex</span></span><br><span class="line"><span class="string">  &quot;&quot;&quot;</span></span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">isinstance</span>(formats, <span class="built_in">str</span>):</span><br><span class="line">      formats = [formats]</span><br><span class="line">  <span class="keyword">return</span> _CAPI_DGLHeteroCreateUnitGraphFromCOO(</span><br><span class="line">      <span class="built_in">int</span>(num_ntypes), <span class="built_in">int</span>(num_src), <span class="built_in">int</span>(num_dst),</span><br><span class="line">      F.to_dgl_nd(row), F.to_dgl_nd(col),</span><br><span class="line">      formats, row_sorted, col_sorted)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;函数 <code>create_unitgraph_from_coo</code> 的传入参数的含义如下所示:

  <ul>
    <li><code>num_ntypes</code>: Unit Graph 上点的种类数 (i.e. 1 或 2)；</li>
    <li><code>num_src</code>: 源节点的数量；</li>
    <li><code>num_dst</code>: 目的节点的数量；</li>
    <li><code>row</code>: 以 COO 形式存储的 Row Index；</li>
    <li><code>col</code>: 以 COO 形式存储的 Column Index；</li>
    <li><code>formats</code>: 一个列表，限制了底层 Unit Graph 存储时使用的矩阵存储形式 (i.e., COO, CSR 和 CSC)。用户传入的 <code>row</code> 和 <code>col</code> 拓扑信息是使用 COO 形式指定的，但是 DGL 在底层转换为 Unit Graph 存储的时候，可以使用其他的格式；</li>
    <li><code>row_sorted</code>: 布尔变量，标识 <code>row</code> 是否进行了排序；</li>
    <li><code>col_sorted</code>: 布尔变量，标识 <code>col</code> 是否进行了排序；</li>
  </ul>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;从 <code>create_unitgraph_from_coo</code> 的代码可以发现，<code>create_unitgraph_from_coo</code> 函数实际上调用了动态链接库中的 <code>_CAPI_DGLHeteroCreateUnitGraphFromCOO</code> 函数。在 <a href="/sec_learning/Algorithm/GNN_DGL_Python_Cpp_Calling/index.html">源码解析：借鉴 TVM 的 Python 和 C++ 的调用机制</a> 一文中我们分析过 DGL 是如何基于 TVM 的 FFI 机制实现 Python 运行时对动态链接库中封装的 API 的调用，我们在这里不再过多赘述。简单来说就是在当前我们分析的 <code>create_unitgraph_from_coo</code> 函数所在的 <code>dgl/heterograph_index.py</code> <cite>dglsrc_heterograph_index_py</cite> 文件中，有以下代码:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> ._ffi.function <span class="keyword">import</span> _init_api</span><br><span class="line"></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">_init_api(<span class="string">&quot;dgl.heterograph_index&quot;</span>)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<code>_init_api</code> 的调用使得当前模块拥有了所有的以 <code>dgl.heterograph_index</code> 为前缀的动态链接库中的 API，其中就包括了我们在这里调用的 <code>_CAPI_DGLHeteroCreateUnitGraphFromCOO</code>。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;另外，值得注意的是，<code>create_unitgraph_from_coo</code> 在调用 <code>_CAPI_DGLHeteroCreateUnitGraphFromCOO</code> 的时候，对于第 4 和第 5 个参数，它使用了我们在 <a href="/sec_learning/Algorithm/GNN_DGL_Memory_Management/index.html">源码解析：DGL 的内存管理方法</a> 中介绍的 <code>F.to_dgl_nd</code> API 实现了 PyTorch Tensor 到 DGL <code>NDArray</code> 的转化。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;现在让我们来看动态链接库中关于 <code>_CAPI_DGLHeteroCreateUnitGraphFromCOO</code> 这个函数的定义，这个函数是在 <code>src/graph/heterograph_capi.cc</code> <cite>dglsrc_src_graph_heterograph_capi_cc</cite> 中被定义的，如下所示:

  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">DGL_REGISTER_GLOBAL(<span class="string">&quot;heterograph_index._CAPI_DGLHeteroCreateUnitGraphFromCOO&quot;</span>)</span><br><span class="line">.set_body([] (DGLArgs args, DGLRetValue* rv) &#123;</span><br><span class="line">    <span class="keyword">int64_t</span> nvtypes = args[<span class="number">0</span>];        <span class="comment">// 节点种类数</span></span><br><span class="line">    <span class="keyword">int64_t</span> num_src = args[<span class="number">1</span>];        <span class="comment">// 源节点个数</span></span><br><span class="line">    <span class="keyword">int64_t</span> num_dst = args[<span class="number">2</span>];        <span class="comment">// 目的节点个数</span></span><br><span class="line">    IdArray row = args[<span class="number">3</span>];            <span class="comment">// Row Index</span></span><br><span class="line">    IdArray col = args[<span class="number">4</span>];            <span class="comment">// Col Index</span></span><br><span class="line">    List&lt;Value&gt; formats = args[<span class="number">5</span>];    <span class="comment">// Unit Graph 的可用存储格式列表</span></span><br><span class="line">    <span class="keyword">bool</span> row_sorted = args[<span class="number">6</span>];</span><br><span class="line">    <span class="keyword">bool</span> col_sorted = args[<span class="number">7</span>];</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 获取代表 Unit Graph 底层存储形式的 code</span></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;SparseFormat&gt; formats_vec;</span><br><span class="line">    <span class="keyword">for</span> (Value val : formats) &#123;</span><br><span class="line">      <span class="built_in">std</span>::<span class="built_in">string</span> fmt = val-&gt;data;</span><br><span class="line">      formats_vec.push_back(ParseSparseFormat(fmt));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">auto</span> code = SparseFormatsToCode(formats_vec);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 在底层创建 Unit Graph</span></span><br><span class="line">    <span class="keyword">auto</span> hgptr = CreateFromCOO(nvtypes, num_src, num_dst, row, col,</span><br><span class="line">        row_sorted, col_sorted, code);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 返回底层 Unit Graph 的指针</span></span><br><span class="line">    *rv = HeteroGraphRef(hgptr);</span><br><span class="line">  &#125;);</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在上面的代码中，<code>_CAPI_DGLHeteroCreateUnitGraphFromCOO</code> 首先对传入的 Unit Graph 的存储格式列表进行了整理，然后生成了指定存储格式的 <code>code</code> 变量。接着在 Line 21 调用了在 <code>rc/graph/creators.cc</code> <cite>dglsrc_src_graph_creators_cc</cite> 中定义的函数 <code>CreateFromCOO</code>，该函数的定义如下所示:

  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">HeteroGraphPtr <span class="title">CreateFromCOO</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int64_t</span> num_vtypes, <span class="keyword">int64_t</span> num_src, <span class="keyword">int64_t</span> num_dst,</span></span></span><br><span class="line"><span class="function"><span class="params">    IdArray row, IdArray col,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">bool</span> row_sorted, <span class="keyword">bool</span> col_sorted, <span class="keyword">dgl_format_code_t</span> formats)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> unit_g = UnitGraph::CreateFromCOO(</span><br><span class="line">      num_vtypes, num_src, num_dst, row, col, row_sorted, col_sorted, formats);</span><br><span class="line">  <span class="keyword">return</span> HeteroGraphPtr(<span class="keyword">new</span> HeteroGraph(unit_g-&gt;meta_graph(), &#123;unit_g&#125;));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;可以发现，<code>CreateFromCOO</code> 实际上调用了 <code>UnitCOO</code> 类的 <code>CreateFromCOO</code> 方法，该方法在 <code>dgl/src/graph/unit_graph.cc</code> <cite>dglsrc_src_graph_unit_graph_cc</cite> 中进行了定义，如下所示:

  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">HeteroGraphPtr <span class="title">UnitGraph::CreateFromCOO</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">int64_t</span> num_vtypes, <span class="keyword">int64_t</span> num_src, <span class="keyword">int64_t</span> num_dst,</span></span></span><br><span class="line"><span class="function"><span class="params">    IdArray row, IdArray col,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">bool</span> row_sorted, <span class="keyword">bool</span> col_sorted,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">dgl_format_code_t</span> formats)</span> </span>&#123;</span><br><span class="line">  CHECK(num_vtypes == <span class="number">1</span> || num_vtypes == <span class="number">2</span>);</span><br><span class="line">  <span class="keyword">if</span> (num_vtypes == <span class="number">1</span>)</span><br><span class="line">    CHECK_EQ(num_src, num_dst);</span><br><span class="line">  <span class="keyword">auto</span> mg = CreateUnitGraphMetaGraph(num_vtypes);</span><br><span class="line">  <span class="function">COOPtr <span class="title">coo</span><span class="params">(<span class="keyword">new</span> COO(mg, num_src, num_dst, row, col,</span></span></span><br><span class="line"><span class="function"><span class="params">      row_sorted, col_sorted))</span></span>;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> HeteroGraphPtr(</span><br><span class="line">      <span class="keyword">new</span> UnitGraph(mg, <span class="literal">nullptr</span>, <span class="literal">nullptr</span>, coo, formats));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;在确认 <code>num_vtypes</code>、<code>num_src</code> 和 <code>num_dst</code> 三者的数值关系无误后，Line 9 调用了 <code>CreateUnitGraphMetaGraph</code> 函数，以基于图中点的种类数 <code>num_vtypes</code> 创建当前 Unit Graph 的 MetaGraph。回顾我们在 <ref>metagraph</ref> 中提到的，对于 Unit Graph 来说，其 Meta Graph 的形式只有两种情况。下面让我们来看 <code>CreateUnitGraphMetaGraph</code> 的具体定义，它位于 <code>src/graph/unit_graph.cc</code> <cite>dglsrc_src_graph_unit_graph_cc</cite> 中。

  <figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> GraphPtr <span class="title">CreateUnitGraphMetaGraph</span><span class="params">(<span class="keyword">int</span> num_vtypes)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">static</span> GraphPtr mg1 = CreateUnitGraphMetaGraph1();</span><br><span class="line">  <span class="keyword">static</span> GraphPtr mg2 = CreateUnitGraphMetaGraph2();</span><br><span class="line">  <span class="keyword">if</span> (num_vtypes == <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> mg1;</span><br><span class="line">  <span class="keyword">else</span> <span class="keyword">if</span> (num_vtypes == <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> mg2;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">    LOG(FATAL) &lt;&lt; <span class="string">&quot;Invalid number of vertex types. Must be 1 or 2.&quot;</span>;</span><br><span class="line">  <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// create metagraph of one node type</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> GraphPtr <span class="title">CreateUnitGraphMetaGraph1</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// a self-loop edge 0-&gt;0</span></span><br><span class="line">  <span class="function"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int64_t</span>&gt; <span class="title">row_vec</span><span class="params">(<span class="number">1</span>, <span class="number">0</span>)</span></span>;</span><br><span class="line">  <span class="function"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int64_t</span>&gt; <span class="title">col_vec</span><span class="params">(<span class="number">1</span>, <span class="number">0</span>)</span></span>;</span><br><span class="line">  IdArray row = aten::VecToIdArray(row_vec);</span><br><span class="line">  IdArray col = aten::VecToIdArray(col_vec);</span><br><span class="line">  GraphPtr g = ImmutableGraph::CreateFromCOO(<span class="number">1</span>, row, col);</span><br><span class="line">  <span class="keyword">return</span> g;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// create metagraph of two node types</span></span><br><span class="line"><span class="function"><span class="keyword">inline</span> GraphPtr <span class="title">CreateUnitGraphMetaGraph2</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="comment">// an edge 0-&gt;1</span></span><br><span class="line">  <span class="function"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int64_t</span>&gt; <span class="title">row_vec</span><span class="params">(<span class="number">1</span>, <span class="number">0</span>)</span></span>;</span><br><span class="line">  <span class="function"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">int64_t</span>&gt; <span class="title">col_vec</span><span class="params">(<span class="number">1</span>, <span class="number">1</span>)</span></span>;</span><br><span class="line">  IdArray row = aten::VecToIdArray(row_vec);</span><br><span class="line">  IdArray col = aten::VecToIdArray(col_vec);</span><br><span class="line">  GraphPtr g = ImmutableGraph::CreateFromCOO(<span class="number">2</span>, row, col);</span><br><span class="line">  <span class="keyword">return</span> g;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;可以发现，<code>CreateUnitGraphMetaGraph</code> 根据 <code>num_vtypes</code> 为 1 或 2 的情况，分别调用 <code>CreateUnitGraphMetaGraph1</code> 或 <code>CreateUnitGraphMetaGraph2</code>，以分别创建带有 1 个或 2 个点的 Meta Graph。值得注意的是，在上面代码的 Line 2~3 中，我们可以发现 <code>CreateUnitGraphMetaGraph</code> 是以 <code>static</code> 的方式创建这两种情况的 Meta Graph，然后根据 <code>num_vtypes</code> 的值返回对应的 Meta Graph 实例。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;

  <h4 class="title">创建 <code>DGLHeteroGraph</code> 实例</h4>

  <h3 class="title">xxx</h3>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;对于无向的图，用户需要为每条边都创建两个方向的边。可以使用 <code>dgl.to_bidirected</code> 函数来实现这个目的。如下面的代码段所示，这个函数可以把原图转换成一个包含反向边的图。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bg = dgl.to_bidirected(g)</span><br><span class="line"></span><br><span class="line">print(bg.edges())</span><br><span class="line"><span class="comment"># (tensor([0, 0, 0, 1, 1, 2, 3, 3]), tensor([1, 2, 3, 0, 3, 0, 0, 1]))</span></span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;值得注意的是，由于 <code>Tensor</code> 类内部使用 C 来存储，且显性定义了数据类型以及存储的设备信息，DGL 推荐使用 <code>Tensor</code> 作为 DGL API 的输入。不过大部分的 DGL API 也支持 Python 的可迭代类型(比如列表)或 <code>numpy.ndarray</code> 类型作为 API 的输入，方便用户快速进行开发验证。

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;DGL 支持使用 32 位或 64 位的整数作为节点 ID 和边 ID。节点和边 ID 的数据类型必须一致。如果使用 64 位整数， DGL 可以处理最多 $2^{63}−1$ 个节点或边。不过，如果图里的节点或者边的数量小于 $2^{63}−1$ ，用户最好使用 $32$ 位整数。 这样不仅能提升速度，还能减少内存的使用。DGL 提供了进行数据类型转换的方法，如下例所示。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">edges = th.tensor([<span class="number">2</span>, <span class="number">5</span>, <span class="number">3</span>]), th.tensor([<span class="number">3</span>, <span class="number">5</span>, <span class="number">0</span>])  <span class="comment"># 边：2-&gt;3, 5-&gt;5, 3-&gt;0</span></span><br><span class="line">g64 = dgl.graph(edges)  <span class="comment"># DGL默认使用int64</span></span><br><span class="line">print(g64.idtype)</span><br><span class="line"><span class="comment"># torch.int64</span></span><br><span class="line"></span><br><span class="line">g32 = dgl.graph(edges, idtype=th.int32)  <span class="comment"># 使用int32构建图</span></span><br><span class="line">print(g32.idtype)</span><br><span class="line"><span class="comment"># torch.int32</span></span><br><span class="line"></span><br><span class="line">g64_2 = g32.long()  <span class="comment"># 转换成int64</span></span><br><span class="line">print(g64_2.idtype)</span><br><span class="line"><span class="comment"># torch.int64</span></span><br><span class="line"></span><br><span class="line">g32_2 = g64.<span class="built_in">int</span>()  <span class="comment"># 转换成int32</span></span><br><span class="line">print(g32_2.idtype)</span><br><span class="line"><span class="comment"># torch.int32</span></span><br></pre></td></tr></table></figure>
</div>

<h2 class="title">节点和边的特征</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;<code>DGLGraph</code> 对象的节点和边可具有多个用户定义的、可命名的特征，以储存图的节点和边的属性。通过 <code>ndata</code> 和 <code>edata</code> 接口可访问这些特征。实例代码如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> th</span><br><span class="line">g = dgl.graph(([<span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">5</span>], [<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">0</span>])) <span class="comment"># 6个节点，4条边</span></span><br><span class="line"></span><br><span class="line">print(g)</span><br><span class="line"><span class="comment"># Graph(num_nodes=6, num_edges=4,</span></span><br><span class="line"><span class="comment">#       ndata_schemes=&#123;&#125;</span></span><br><span class="line"><span class="comment">#       edata_schemes=&#123;&#125;)</span></span><br><span class="line"></span><br><span class="line">g.ndata[<span class="string">&#x27;x&#x27;</span>] = th.ones(g.num_nodes(), <span class="number">3</span>)               <span class="comment"># 长度为3的节点特征</span></span><br><span class="line">g.edata[<span class="string">&#x27;x&#x27;</span>] = th.ones(g.num_edges(), dtype=th.int32)  <span class="comment"># 标量整型特征</span></span><br><span class="line"></span><br><span class="line">print(g)</span><br><span class="line"><span class="comment"># Graph(num_nodes=6, num_edges=4,</span></span><br><span class="line"><span class="comment">#       ndata_schemes=&#123;&#x27;x&#x27; : Scheme(shape=(3,), dtype=torch.float32)&#125;</span></span><br><span class="line"><span class="comment">#       edata_schemes=&#123;&#x27;x&#x27; : Scheme(shape=(,), dtype=torch.int32)&#125;)</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 不同名称的特征可以具有不同形状</span></span><br><span class="line">g.ndata[<span class="string">&#x27;y&#x27;</span>] = th.randn(g.num_nodes(), <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取节点1的特征</span></span><br><span class="line">print(g.ndata[<span class="string">&#x27;x&#x27;</span>][<span class="number">1</span>])                  </span><br><span class="line"><span class="comment"># tensor([1., 1., 1.])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取边0和3的特征</span></span><br><span class="line">print(g.edata[<span class="string">&#x27;x&#x27;</span>][th.tensor([<span class="number">0</span>, <span class="number">3</span>])])  </span><br><span class="line"><span class="comment"># tensor([1, 1], dtype=torch.int32)</span></span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;关于 <code>ndata</code> 和 <code>edata</code> 接口，它们有如下特征:

  <ul>
    <li>仅允许使用数值类型 (如单精度浮点型、双精度浮点型和整型) 的特征，这些特征可以是标量、向量或多维张量;</li>
    <li>每个节点特征具有唯一名称，每个边特征也具有唯一名称。节点和边的特征可以具有相同的名称;</li>
    <li>通过张量分配创建特征时，DGL 会将特征赋给图中的每个节点和每条边。该张量的第一维必须与图中节点或边的数量一致，不能将特征赋给图中节点或边的子集;</li>
    <li>相同名称的特征必须具有相同的维度和数据类型;</li>
    <li>特征张量使用 "行优先" 的原则，即每个行切片储存 $1$ 个节点或 $1$ 条边的特征</li>
  </ul>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;另外，对于加权图，用户可以将权重储存为一个边特征，例子如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 边 0-&gt;1, 0-&gt;2, 0-&gt;3, 1-&gt;3</span></span><br><span class="line">edges = th.tensor([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line">weights = th.tensor([<span class="number">0.1</span>, <span class="number">0.6</span>, <span class="number">0.9</span>, <span class="number">0.7</span>])  <span class="comment"># 每条边的权重</span></span><br><span class="line">g = dgl.graph(edges)</span><br><span class="line">g.edata[<span class="string">&#x27;w&#x27;</span>] = weights  <span class="comment"># 将其命名为 &#x27;w&#x27;</span></span><br><span class="line"></span><br><span class="line">print(g)</span><br><span class="line"><span class="comment"># Graph(num_nodes=4, num_edges=4,</span></span><br><span class="line"><span class="comment">#       ndata_schemes=&#123;&#125;</span></span><br><span class="line"><span class="comment">#       edata_schemes=&#123;&#x27;w&#x27; : Scheme(shape=(,), dtype=torch.float32)&#125;)</span></span><br></pre></td></tr></table></figure>
</div>

<h2 class="title">异构图</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;相比同构图，异构图里可以有不同类型的节点和边。这些不同类型的节点和边具有独立的 ID 空间和特征。在 DGL 中，一个异构图由一系列子图构成，<note>一个子图对应一种关系</note>。每个关系由一个字符串三元组定义 <code>(源节点类型, 边类型, 目标节点类型)</code>。由于这里的关系定义消除了边类型的歧义，DGL 称它们为 canonical edge types。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> th</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a heterograph with 3 node types and 3 edges types.</span></span><br><span class="line">graph_data = &#123;</span><br><span class="line">  (<span class="string">&#x27;drug&#x27;</span>, <span class="string">&#x27;interacts&#x27;</span>, <span class="string">&#x27;drug&#x27;</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>])),</span><br><span class="line">  (<span class="string">&#x27;drug&#x27;</span>, <span class="string">&#x27;interacts&#x27;</span>, <span class="string">&#x27;gene&#x27;</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">2</span>, <span class="number">3</span>])),</span><br><span class="line">  (<span class="string">&#x27;drug&#x27;</span>, <span class="string">&#x27;treats&#x27;</span>, <span class="string">&#x27;disease&#x27;</span>): (th.tensor([<span class="number">1</span>]), th.tensor([<span class="number">2</span>]))</span><br><span class="line">&#125;</span><br><span class="line">g = dgl.heterograph(graph_data)</span><br><span class="line"></span><br><span class="line">print(g.ntypes)</span><br><span class="line"><span class="comment"># [&#x27;disease&#x27;, &#x27;drug&#x27;, &#x27;gene&#x27;]</span></span><br><span class="line"></span><br><span class="line">print(g.etypes)</span><br><span class="line"><span class="comment"># [&#x27;interacts&#x27;, &#x27;interacts&#x27;, &#x27;treats&#x27;]</span></span><br><span class="line"></span><br><span class="line">print(g.canonical_etypes)</span><br><span class="line"><span class="comment"># [(&#x27;drug&#x27;, &#x27;interacts&#x27;, &#x27;drug&#x27;),</span></span><br><span class="line"><span class="comment"># (&#x27;drug&#x27;, &#x27;interacts&#x27;, &#x27;gene&#x27;),</span></span><br><span class="line"><span class="comment"># (&#x27;drug&#x27;, &#x27;treats&#x27;, &#x27;disease&#x27;)]</span></span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;这么看来，同构图和二分图只是一种特殊的异构图，它们只包括一种关系。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 一个同构图</span></span><br><span class="line">dgl.heterograph(&#123;(<span class="string">&#x27;node_type&#x27;</span>, <span class="string">&#x27;edge_type&#x27;</span>, <span class="string">&#x27;node_type&#x27;</span>): (u, v)&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一个二分图</span></span><br><span class="line">dgl.heterograph(&#123;(<span class="string">&#x27;source_type&#x27;</span>, <span class="string">&#x27;edge_type&#x27;</span>, <span class="string">&#x27;destination_type&#x27;</span>): (u, v)&#125;)</span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;与异构图相关联的 metagraph 就是图的模式。它指定节点集和节点之间的边的类型约束。 metagraph 中的一个节点 $u$ 对应于相关异构图中的一个节点类型。metagraph 中的边 $(u,v)$ 表示在相关异构图中存在从 $u$ 型节点到 $v$ 型节点的边。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">print(g)</span><br><span class="line"><span class="comment"># Graph(num_nodes=&#123;&#x27;disease&#x27;: 3, &#x27;drug&#x27;: 3, &#x27;gene&#x27;: 4&#125;,</span></span><br><span class="line"><span class="comment">#       num_edges=&#123;(&#x27;drug&#x27;, &#x27;interacts&#x27;, &#x27;drug&#x27;): 2,</span></span><br><span class="line"><span class="comment">#                 (&#x27;drug&#x27;, &#x27;interacts&#x27;, &#x27;gene&#x27;): 2,</span></span><br><span class="line"><span class="comment">#                 (&#x27;drug&#x27;, &#x27;treats&#x27;, &#x27;disease&#x27;): 1&#125;,</span></span><br><span class="line"><span class="comment">#       metagraph=[(&#x27;drug&#x27;, &#x27;drug&#x27;, &#x27;interacts&#x27;),</span></span><br><span class="line"><span class="comment">#                 (&#x27;drug&#x27;, &#x27;gene&#x27;, &#x27;interacts&#x27;),</span></span><br><span class="line"><span class="comment">#                 (&#x27;drug&#x27;, &#x27;disease&#x27;, &#x27;treats&#x27;)])</span></span><br><span class="line"></span><br><span class="line">print(g.metagraph().edges())</span><br><span class="line"><span class="comment"># OutMultiEdgeDataView([(&#x27;drug&#x27;, &#x27;drug&#x27;), (&#x27;drug&#x27;, &#x27;gene&#x27;), (&#x27;drug&#x27;, &#x27;disease&#x27;)])</span></span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;当引入多种节点和边类型后，用户在调用 DGLGraph API 以获取特定类型的信息时，需要指定具体的节点和边类型。此外，不同类型的节点和边具有单独的 ID。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 获取图中所有节点的数量</span></span><br><span class="line">print(g.num_nodes())</span><br><span class="line"><span class="comment"># 10</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 获取drug节点的数量</span></span><br><span class="line">print(g.num_nodes(<span class="string">&#x27;drug&#x27;</span>))</span><br><span class="line"><span class="comment"># 3</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 不同类型的节点有单独的ID。因此，没有指定节点类型就没有明确的返回值。</span></span><br><span class="line">print(g.nodes())</span><br><span class="line"><span class="comment"># DGLError: Node type name must be specified if there are more than one node types.</span></span><br><span class="line"></span><br><span class="line">print(g.nodes(<span class="string">&#x27;drug&#x27;</span>))</span><br><span class="line"><span class="comment"># tensor([0, 1, 2])</span></span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;为了设置/获取特定节点和边类型的特征，DGL 提供了两种新类型的语法:

  <ul>
    <li>获取特定点类型的特征: <code>g.nodes[‘node_type’].data[‘feat_name’]</code></li>
    <li>获取特定边类型的特征: <code>g.edges[‘edge_type’].data[‘feat_name’]</code></li>
  </ul>

  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;示例代码如下所示:

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 设置/获取&quot;drug&quot;类型的节点的&quot;hv&quot;特征</span></span><br><span class="line">g.nodes[<span class="string">&#x27;drug&#x27;</span>].data[<span class="string">&#x27;hv&#x27;</span>] = th.ones(<span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">print(g.nodes[<span class="string">&#x27;drug&#x27;</span>].data[<span class="string">&#x27;hv&#x27;</span>])</span><br><span class="line"><span class="comment"># tensor([[1.],</span></span><br><span class="line"><span class="comment">#         [1.],</span></span><br><span class="line"><span class="comment">#         [1.]])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置/获取&quot;treats&quot;类型的边的&quot;he&quot;特征</span></span><br><span class="line">g.edges[<span class="string">&#x27;treats&#x27;</span>].data[<span class="string">&#x27;he&#x27;</span>] = th.zeros(<span class="number">1</span>, <span class="number">1</span>)</span><br><span class="line">print(g.edges[<span class="string">&#x27;treats&#x27;</span>].data[<span class="string">&#x27;he&#x27;</span>])</span><br><span class="line"><span class="comment"># tensor([[0.]])</span></span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;如果图里只有一种节点或边类型，则不需要指定节点或边的类型。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">g = dgl.heterograph(&#123;</span><br><span class="line">  (<span class="string">&#x27;drug&#x27;</span>, <span class="string">&#x27;interacts&#x27;</span>, <span class="string">&#x27;drug&#x27;</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">1</span>, <span class="number">2</span>])),</span><br><span class="line">  (<span class="string">&#x27;drug&#x27;</span>, <span class="string">&#x27;is similar&#x27;</span>, <span class="string">&#x27;drug&#x27;</span>): (th.tensor([<span class="number">0</span>, <span class="number">1</span>]), th.tensor([<span class="number">2</span>, <span class="number">3</span>]))</span><br><span class="line">&#125;)</span><br><span class="line"></span><br><span class="line">print(g.nodes())</span><br><span class="line"><span class="comment"># tensor([0, 1, 2, 3])</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 设置/获取单一类型的节点或边特征，不必使用新的语法</span></span><br><span class="line">g.ndata[<span class="string">&#x27;hv&#x27;</span>] = th.ones(<span class="number">4</span>, <span class="number">1</span>)</span><br></pre></td></tr></table></figure>
</div>

<h2 class="title">在 GPU 上使用 DGLGraph</h2>
<div class="div_learning_post">
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;用户可以通过在构造图的过程中传入两个 GPU 张量来创建 GPU 上的 <code>DGLGraph</code>。另一种方法是使用 <code>to</code> API 将 <code>DGLGraph</code> 复制到 GPU，这会将图结构和特征数据都拷贝到指定的设备。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> dgl</span><br><span class="line"><span class="keyword">import</span> torch <span class="keyword">as</span> th</span><br><span class="line">u, v = th.tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>]), th.tensor([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>])</span><br><span class="line">g = dgl.graph((u, v))</span><br><span class="line">g.ndata[<span class="string">&#x27;x&#x27;</span>] = th.randn(<span class="number">5</span>, <span class="number">3</span>)   <span class="comment"># 原始特征在CPU上</span></span><br><span class="line"></span><br><span class="line">print(g.device)</span><br><span class="line"><span class="comment"># device(type=&#x27;cpu&#x27;)</span></span><br><span class="line"></span><br><span class="line">cuda_g = g.to(<span class="string">&#x27;cuda:0&#x27;</span>)         <span class="comment"># 接受来自后端框架的任何设备对象</span></span><br><span class="line">print(cuda_g.device)</span><br><span class="line"><span class="comment"># device(type=&#x27;cuda&#x27;, index=0)</span></span><br><span class="line"></span><br><span class="line">print(cuda_g.ndata[<span class="string">&#x27;x&#x27;</span>].device) <span class="comment"># 特征数据也拷贝到了GPU上</span></span><br><span class="line">device(<span class="built_in">type</span>=<span class="string">&#x27;cuda&#x27;</span>, index=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 由GPU张量构造的图也在GPU上</span></span><br><span class="line">u, v = u.to(<span class="string">&#x27;cuda:0&#x27;</span>), v.to(<span class="string">&#x27;cuda:0&#x27;</span>)</span><br><span class="line">g = dgl.graph((u, v))</span><br><span class="line">print(g.device)</span><br><span class="line"><span class="comment"># device(type=&#x27;cuda&#x27;, index=0)</span></span><br></pre></td></tr></table></figure>
  <p>
  &nbsp;&nbsp;&nbsp;&nbsp;任何涉及在 GPU 上存储的图的操作都是在 GPU 上运行的。因此，这要求所有张量参数都已经放在GPU上，其结果(图或张量)也将在 GPU 上。此外，在 GPU 上存储的图只接受 GPU 上的特征数据。

  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">print(cuda_g.in_degrees())</span><br><span class="line"><span class="comment"># tensor([0, 0, 1, 1, 1], device=&#x27;cuda:0&#x27;)</span></span><br><span class="line"></span><br><span class="line">print(cuda_g.in_edges([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]))                         <span class="comment"># 可以接受非张量类型的参数</span></span><br><span class="line">(tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>), tensor([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>))</span><br><span class="line"></span><br><span class="line">print(cuda_g.in_edges(th.tensor([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>]).to(<span class="string">&#x27;cuda:0&#x27;</span>))) <span class="comment"># 张量类型的参数必须在GPU上</span></span><br><span class="line">(tensor([<span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>), tensor([<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>], device=<span class="string">&#x27;cuda:0&#x27;</span>))</span><br><span class="line"></span><br><span class="line">print(cuda_g.ndata[<span class="string">&#x27;h&#x27;</span>] = th.randn(<span class="number">5</span>, <span class="number">4</span>))                 <span class="comment"># ERROR! 特征也必须在GPU上！</span></span><br><span class="line"><span class="comment"># DGLError: Cannot assign node feature &quot;h&quot; on device cpu to a graph on device</span></span><br><span class="line"><span class="comment"># cuda:0. Call DGLGraph.to() to copy the graph to the same device.</span></span><br></pre></td></tr></table></figure>
</div>

<div class="div_ref" id="ref_container"></div>

</body>


<!--图片、引用-->
<!-- 
<div class="img" title="img title" label="img_label">
  <img src="" height="" />
</div>

<imaging>img_label</imaging>
-->

<!--等式、引用-->
<!-- 
<div class="equation" label="equation_label">
</div>

<equation>equation_label</equation>
-->

<!--定理、引用、证明-->
<!-- 
<div class="theorm" label="theorm_label">
</div>

<theorm>theorm_label</theorm>

<div class="theorm_prove">
</div>
-->

<!--引用其它章节-->
<!-- 
<ref></ref> 
-->

<!--引用文献-->
<!-- 
<cite></cite> 
-->

<!--关键词-->
<!-- 
<def></def> 
-->

<!--醒目注意-->
<!-- 
<note></note> 
-->

<!--表格-->
<!--
<table border="1" align="center" bgcolor="#FFFFFF">
  <caption>表格</caption>
  <tr>
    <th>A</th>
    <th>B</th>
    <th>C</th>
  </tr>
  <tr>
    <td>xxx</td>
    <td>xxx</td>
    <td>xxx</td>
  </tr>
</table>
-->

<!--矩阵公式-->
<!--
<div class="cmath" align="center">
  `((1, 0),(1, 0))`
</div><br>
-->

<!--伪代码-->
<!--
<pre id="quicksort" style="display:hidden;">
  % This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
  \begin{algorithm}
  \caption{Quicksort}
  \begin{algorithmic}
  \PROCEDURE{Quicksort}{$A, p, r$}
      % Add Here

      % 空行
      % \STATE \texttt{\\}
  \ENDPROCEDURE
  \end{algorithmic}
  \end{algorithm}
</pre>
<script>
    pseudocode.renderElement(document.getElementById("quicksort"));
</script>
-->
<!--
Latex 伪代码格式见: https://github.com/SaswatPadhi/pseudocode.js
-->

<!--图片-->
<!--
<div align="center">
  <img src="./pic/xxx.png" width=80%>
</div>
-->

<!--正文-->
<!--
<p>
&nbsp;&nbsp;&nbsp;&nbsp;公式：<span>`\overline{A}\overline{B}`</span>
</p>
-->
      </div>
      
      
      
    </div>
    
  <ul class="breadcrumb">
          
            <li><a href="/sec_learning/">SEC_LEARNING</a></li>
            <li><a href="/sec_learning/Algorithm/">ALGORITHM</a></li>
          <li>GNN_DGL_GRAPH_CONSTRUCTION</li>
        
  </ul>

    
    
    


          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Inhaltsverzeichnis
        </li>
        <li class="sidebar-nav-overview">
          Übersicht
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Zhuobin Huang"
      src="/images/avatar.png">
  <p class="site-author-name" itemprop="name">Zhuobin Huang</p>
  <div class="site-description" itemprop="description">System Engineer</div>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/zobinHuang" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;zobinHuang" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:zobin1999@gmail.com" title="E-Mail → mailto:zobin1999@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.weibo.com/u/2861056530" title="Weibo → https:&#x2F;&#x2F;www.weibo.com&#x2F;u&#x2F;2861056530" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://twitter.com/HwangZobin" title="Twitter → https:&#x2F;&#x2F;twitter.com&#x2F;HwangZobin" rel="noopener" target="_blank"><i class="fab fa-twitter fa-fw"></i>Twitter</a>
      </span>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        
  <div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">粤ICP备2021044371号 </a>
  </div>

<div class="copyright">
  
  &copy; 2017 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-guitar"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhuobin Huang</span>
</div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>

<script src="/js/bookmark.js"></script>




  
  <script>
    (function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();
  </script>















  

  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'y8LMT8RtOsi4JsbYHtNm2J7U-gzGzoHsz',
      appKey     : 'Q0cSe4rR8Iwr0Gs60rwWBsYa',
      placeholder: "Just go go",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
